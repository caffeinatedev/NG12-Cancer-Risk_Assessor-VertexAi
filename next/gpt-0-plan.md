Hereâ€™s a **clear breakdown of what your `whatâ€‘isâ€‘itâ€‘about.md` most likely *doesnâ€™t* include yet** and what you need to get you started immediately â€” based on the screenshots you shared of the Slack message and the partial PDF.

Iâ€™m not pulling extra proprietary content from the PDF â€” Iâ€™m extracting whatâ€™s visible and mapping that into a detailed **starter plan**.

---

## âœ… **1. What the Assessment *Actually Is***

From the Slack message snippet:

* Itâ€™s a **takeâ€‘home technical assessment** due **January 7, 2026**.
* It is designed to take **~5â€“7 hours.**
* It focuses on building a **reasoning agent** that:

  * Combines **structured patient data** with **unstructured clinical guidelines**.
  * Reuses a **single RAG (retrievalâ€‘augmented generation) pipeline** across:

    * A **clinical decision support workflow**.
    * A **conversational chatâ€‘based interface**.
* Youâ€™ll find *full* instructions in the attached challenge brief.
  (Your MD file may only have a summary â€” not all details.)

This means the *core goal* is **architecture, reasoning design, grounding, tooling** â€” not just a UI.
The reviewers care how *you* design and justify your solution.

**Missing from many summaries:**
âœ” What the assessment *is about* (this should be expanded)
âœ” Emphasis on RAG pipeline reuse
âœ” Dual workflows â€” clinical and chat interface
âœ” Time estimate (5â€“7 hrs)

---

## âœ… **2. Deliverables You Need to Clarify**

Your minimal `whatâ€‘isâ€‘itâ€‘about.md` likely does *not* yet list these clearly:

**Final deliverables:**

1. **Code repository** (public or private invite)
2. **Implementation of the reasoning agent**

   * a clinical decision support workflow
   * a conversational/chat interface
3. **RAG pipeline reused between both modes**
4. **Readme / documentation**

   * How to run the project
   * Architecture diagram
   * Assumptions and tradeâ€‘offs
5. **Brief notes to reviewers**

   * What you would improve with more time
   * Why you chose this approach

**Checklist to add if missing:**

* Deployment instructions
* Test cases or demonstration scripts
* Data samples (if any synthetic data used)

---

## âœ… **3. Technical Stack Considerations**

The partial PDF shows something like:

> *Build a Clinical Decision Support Agent using **Google Vertex AI (Gemini 1.5)**â€¦*

So the stack likely expected (but your MD may miss):

ğŸ“Œ **Core ML/LLM Infrastructure**

* **Google Vertex AI** (Gemini 1.5 â€‘ mentioned in the PDF screenshot)
* RAG setup (vector store + Retriever + LLM)
* Embeddings (Vertex AI or alternative)

ğŸ“Œ **Backend**

* Python/Node.js or similar language
* Web framework (FastAPI, Flask, Next.js API routes)

ğŸ“Œ **Frontâ€‘end**

* Chatâ€‘based interface (React/Next.js/Vue)
* Simple UI to query the agent

ğŸ“Œ **Data**

* Structured patient data (CSV/JSON)
* Unstructured clinical guidelines (e.g., NICE NG12 national suspected cancer guideline)
  NICE NG12 is the reputed clinical guideline used for suspected cancer referrals. It contains symptom/criteria logic for decision rules â€” exactly what your *clinical decision workflow* needs to reason over. ([Cancer Research UK][1])

ğŸ“Œ **Vector Store**

* Pinecone / Milvus / Weaviate / Vertex AI Matching Engine

ğŸ“Œ **Testing**

* Unit tests for pipeline
* Integration test for chat agent

**Your MD may not yet call out:**

* Stack specifics (Vertex, vector store choices, frontend tech)
* Dependencies and versions
* Deployment considerations

---

## âœ… **4. Requirements & Criteria for â€œPassingâ€**

Your current MD probably *doesnâ€™t* include any grading criteria, because **none is stated explicitly in the Slack text** â€” but you can *infer* what reviewers will judge.

### **What reviewers care about**

âœ” **Correctness of the reasoning agent**
âœ” **Quality of the architecture**
âœ” **Reusability of the RAG pipeline**
âœ” **Cleanliness & readability of code**
âœ” **Documentation & justification of design choices**
âœ” **Tradeâ€‘offs, assumptions, and future improvements**
âœ” **Minimal working UX**

### **Likely implicit grading rubric**

| Category      | What to include                           |
| ------------- | ----------------------------------------- |
| Functionality | Working RAG agent with both UIs           |
| Design        | Clear modular architecture                |
| Grounding     | RAG retrieves real guideline text         |
| Reasoning     | Correct clinical decisions for test cases |
| Tooling       | Use of Vertex AI (if specified)           |
| Documentation | Clear README + rationale                  |
| Quality       | Testing, structure, code quality          |

---

## âœ… **5. Ambiguities Your MD Should Resolve**

Your current summary might *not yet address*:

â“ Are you expected to host it (Vercel/Cloud Run)?
â“ Does the pipeline need to connect to a real medical dataset?
â“ What format should patient structured data be?
â“ How do we simulate NICE guideline logic?
â“ How thorough is the chat interface?
â“ How to score answers clinically?

You should draft clarifying questions for the hiring team *before coding* â€” e.g., data format expectations, scoring rubric, allowed libraries.

---

## âœ… **6. First Immediate Action Plan**

Below is a **stepâ€‘byâ€‘step actionable plan** you can start *today*:

---

### **Step 1 â€” Fully read the attached PDF**

You must extract:
âœ” Full requirements
âœ” Part 1 / Part 2 descriptions
âœ” Input/Output expectations
âœ” Example cases

If you canâ€™t OCR/read the PDF automatically, upload it to an LLM and ask it to extract sections.

---

### **Step 2 â€” Define Requirements in Your MD**

Add these headings:

```
## Objective
## Deliverables
## Technical Stack
## Input & Output Expectations
## Success Criteria
## Assumptions
```

Populate with what you learned.

---

### **Step 3 â€” Research Clinical Guideline**

* Download NICE NG12 suspected cancer guideline
* Identify decision rules (symptoms â†’ referrals)
  (You can cite free NICE summary as reference.) ([Cancer Research UK][1])

This will become your ground truth for the clinical workflow.

---

### **Step 4 â€” Design Architecture**

Create a diagram showing:

```
Patient Data --\
                Vector Embedder â†’ Vector Store â†’ Retriever â†” LLM
Clinical Text --/
                                  â†˜ Conversational UI
                                  â†˜ Clinical Decision API
```

Document each component.

---

### **Step 5 â€” Pick Tools**

Decide concretely:

| Component     | Choice                            |
| ------------- | --------------------------------- |
| LLM           | Vertex Gemini 1.5                 |
| Embeddings    | Vertex Embeddings                 |
| Vector Store  | Vertex Matching Engine / Pinecone |
| Backend       | FastAPI (Python)                  |
| Frontend      | Next.js (React)                   |
| Hosting       | Google Cloud                      |
| Docs & Readme | Markdown in repo                  |

---

### **Step 6 â€” Build a Minimal Viable Version**

Deliver first:

âœ” RAG pipeline
âœ” Simple conversational frontend
âœ” Simple clinical decision API returning structured output

Test with synthetic data.

---

### **Step 7 â€” Write Tests**

Cover:

* RAG retrieval
* Decision logic (NG12 rules)
* Chat intents

---

### **Step 8 â€” Finalize Documentation**

In repo:

```
README.md
ARCHITECTURE.md
ASSUMPTIONS_AND_TRADEOFFS.md
RUN_INSTRUCTIONS.md
```

---

## ğŸ§  Summary of What Your MD Needs to Add

If any of these are *missing*, add:

âœ… Full deliverables list
âœ… Stack choices
âœ… Expected I/O formats
âœ… Inline success criteria
âœ… Example tests
âœ… Deployment instructions
âœ… Tradeâ€‘offs and assumptions
âœ… Clarifying questions

---

If you want, **paste the current contents of your whatâ€‘isâ€‘itâ€‘about.md** and I can mark exactly what lines to add or revise.

[1]: https://www.cancerresearchuk.org/health-professional/diagnosis/primary-care/suspected-cancer-referral-guidelines/nice-ng12?utm_source=chatgpt.com "NICE (NG12) Suspected Cancer: Recognition & Referral ..."
